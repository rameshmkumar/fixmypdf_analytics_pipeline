name: Data Quality Monitoring

on:
  # Run after the automated ETL completes
  workflow_run:
    workflows: ["Automated ETL Pipeline"]
    types:
      - completed
  
  # Allow manual triggering
  workflow_dispatch:

jobs:
  data-quality-check:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download ETL Results
      uses: actions/download-artifact@v3
      with:
        name: etl-database-${{ github.event.workflow_run.run_number }}
        path: data/
        
    - name: Run Data Quality Checks
      run: |
        echo "ğŸ” RUNNING DATA QUALITY CHECKS"
        echo "=============================="
        
        python -c "
        import duckdb
        from datetime import datetime, timedelta
        
        conn = duckdb.connect('data/dashboard_analytics.duckdb')
        
        print('ğŸ“Š DATA QUALITY REPORT')
        print('=' * 30)
        
        # Check 1: Table record counts
        tables = {
            'fact_analytics': {'min': 100, 'description': 'Event records'},
            'fact_daily_kpis': {'min': 10, 'description': 'Daily aggregations'},
            'dim_tools': {'min': 20, 'description': 'PDF tools'},
            'dim_time': {'min': 5, 'description': 'Time periods'}
        }
        
        print('\\n1. RECORD COUNT VALIDATION:')
        all_good = True
        for table, config in tables.items():
            count = conn.execute(f'SELECT COUNT(*) FROM {table}').fetchone()[0]
            status = 'âœ…' if count >= config['min'] else 'âŒ'
            print(f'   {status} {table}: {count} records ({config[\"description\"]})')
            if count < config['min']:
                all_good = False
        
        # Check 2: Data freshness
        print('\\n2. DATA FRESHNESS CHECK:')
        latest = conn.execute('SELECT MAX(created_at) FROM fact_analytics').fetchone()[0]
        if latest:
            from datetime import datetime
            if isinstance(latest, str):
                latest_dt = datetime.fromisoformat(latest.replace('Z', '+00:00'))
            else:
                latest_dt = latest
            
            hours_old = (datetime.now() - latest_dt.replace(tzinfo=None)).total_seconds() / 3600
            status = 'âœ…' if hours_old < 48 else 'âŒ'
            print(f'   {status} Latest data: {latest} ({hours_old:.1f} hours old)')
            if hours_old >= 48:
                all_good = False
        
        # Check 3: Key metrics validation
        print('\\n3. KEY METRICS VALIDATION:')
        downloads = conn.execute('SELECT SUM(total_downloads) FROM fact_daily_kpis').fetchone()[0]
        uploads = conn.execute('SELECT SUM(total_uploads) FROM fact_daily_kpis').fetchone()[0]
        
        status = 'âœ…' if downloads > 0 and uploads > 0 else 'âŒ'
        print(f'   {status} Downloads: {downloads}, Uploads: {uploads}')
        if downloads == 0 or uploads == 0:
            all_good = False
        
        # Check 4: Referential integrity
        print('\\n4. REFERENTIAL INTEGRITY:')
        orphans = conn.execute('''
            SELECT COUNT(*) FROM fact_analytics f 
            WHERE f.tool_key NOT IN (SELECT tool_key FROM dim_tools)
        ''').fetchone()[0]
        
        status = 'âœ…' if orphans == 0 else 'âŒ'
        print(f'   {status} Orphaned fact records: {orphans}')
        if orphans > 0:
            all_good = False
        
        # Summary
        print(f'\\nğŸ“‹ OVERALL STATUS: {\"âœ… PASSED\" if all_good else \"âŒ FAILED\"}')
        
        conn.close()
        
        if not all_good:
            exit(1)
        "
        
    - name: Generate Quality Report
      if: always()
      run: |
        echo "ğŸ“„ Generating data quality report..."
        
        cat > data_quality_summary.md << 'EOF'
        # Data Quality Report
        
        **Report Date:** $(date)
        **Workflow Run:** ${{ github.run_id }}
        
        ## Summary
        - âœ… Automated data quality checks completed
        - ğŸ“Š Database validated against quality standards  
        - ğŸ”„ ETL pipeline health confirmed
        
        ## Next Steps
        - Dashboard can safely use this data
        - BI tools connected to database will show fresh data
        - Monitor future runs for any quality degradation
        
        ---
        *Generated by automated data quality workflow*
        EOF
        
    - name: Upload Quality Report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: data-quality-report-${{ github.run_number }}
        path: data_quality_summary.md
        retention-days: 90
        
    - name: Notify on Quality Issues
      if: failure()
      run: |
        echo "ğŸš¨ DATA QUALITY ISSUES DETECTED!"
        echo "Please review the ETL pipeline and data sources."
        echo "Dashboard may show inconsistent data until resolved."